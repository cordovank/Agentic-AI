{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e424bc0",
   "metadata": {},
   "source": [
    "# **ProductLens** - An AI-powered product comparison tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394b15ed",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "**ProductLens** helps users compare products and services based on *their* priorities (e.g., privacy, price, ease of setup, brand). It demonstrates a lightweight agentic workflow: user intent → planning → parallel research → comparison → recommendation. \n",
    "\n",
    "<br>\n",
    "\n",
    "![ProductLens](../img/productlens.png)\n",
    "\n",
    "**Flow**\n",
    "\n",
    "A central manager orchestrates planning, parallel product research, and final comparison, ensuring each agent does one focused job and produces an explainable, decision-ready result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dea84ef",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9b257",
   "metadata": {},
   "source": [
    "**Required**\n",
    "- Python 3.10+, gradio, python-dotenv, pydantic, asyncio\n",
    "\n",
    "**LLM / Search (choose one)**\n",
    "- **($$) OpenAI**\n",
    "    - OPENAI_API_KEY in .env\n",
    "    - Uses OpenAI models + `WebSearchTool`\n",
    "    - Traces logs (no charges for this one)\n",
    "- **(Free) Ollama**\n",
    "    - Ollama model in local.\n",
    "    - Ollama API KEY (need to create an account)\n",
    "    - Uses [Ollama's web search API](https://docs.ollama.com/capabilities/web-search)\n",
    "\n",
    "**Configurable**\n",
    "- MODEL (e.g., `gpt-4o-mini`, local Ollama like `gpt-oss`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3c3c5",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "- Create .env with chosen API key\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927c38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from agents import Agent, trace, OpenAIChatCompletionsModel, Model, ModelProvider, Runner, gen_trace_id, function_tool\n",
    "from agents.model_settings import ModelSettings\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5620f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb8e85",
   "metadata": {},
   "source": [
    "### Configure Model\n",
    "\n",
    "Set MODEL variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b4627d",
   "metadata": {},
   "source": [
    "#### OpenAI\n",
    "\n",
    "```python\n",
    "MODEL = \"gpt-5-nano\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8939e",
   "metadata": {},
   "source": [
    "#### Local Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6870a87",
   "metadata": {},
   "source": [
    "If using Ollama, you can use OpenAI’s Agents SDK with `gpt-oss` locally ([more info](https://cookbook.openai.com/articles/gpt-oss/run-locally-ollama#pick-your-model)).\n",
    "\n",
    "We just need a quick setup for compatibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6200d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OllamaProvider(ModelProvider):\n",
    "    def __init__(self):\n",
    "        self.base_url = \"http://localhost:11434/v1\"\n",
    "        self.api_key = \"ollama\"\n",
    "    \n",
    "    def get_async_client(self):\n",
    "        return AsyncOpenAI(\n",
    "            base_url=self.base_url, \n",
    "            api_key=self.api_key\n",
    "            )\n",
    "\n",
    "    def get_model(self, model_name: str) -> Model:\n",
    "        return OpenAIChatCompletionsModel(\n",
    "            openai_client=self.get_async_client(), \n",
    "            model=model_name\n",
    "            )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867dfb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OllamaProvider()\n",
    "MODEL = ollama.get_model(model_name=\"gpt-oss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc561e",
   "metadata": {},
   "source": [
    "# Complete Flow\n",
    "\n",
    "**1. Comparison Manager (Orchestrator)**\n",
    "\n",
    "* Entry point for the user query\n",
    "* Coordinates all agents\n",
    "* Manages async execution and data flow\n",
    "* Owns the end-to-end lifecycle\n",
    "\n",
    "**2. Planner Agent**\n",
    "\n",
    "* Parses the user query and priorities\n",
    "* Identifies relevant products/ecosystems to compare\n",
    "* Derives evaluation criteria\n",
    "* Outputs a structured plan (products + criteria)\n",
    "\n",
    "\n",
    "**3. Product Research Agents (Parallel)**\n",
    "\n",
    "* Spawned by the Comparison Manager\n",
    "* Each researches one product\n",
    "* Uses web search focused on planner criteria\n",
    "* Returns concise product summaries\n",
    "\n",
    "**4. Comparator / Decision Agent**\n",
    "\n",
    "* Invoked by the Comparison Manager\n",
    "* Normalizes research results\n",
    "* Evaluates each product against the criteria\n",
    "* Produces recommendation, table, and tradeoffs\n",
    "\n",
    "\n",
    "**How They Come Together**\n",
    "\n",
    "```text\n",
    "User Query\n",
    "   ↓\n",
    "Comparison Manager\n",
    "   ↓\n",
    "Planner Agent\n",
    "   ↓\n",
    "Parallel Product Research Agents\n",
    "   ↓\n",
    "Comparator Agent\n",
    "   ↓\n",
    "Final Recommendation\n",
    "```\n",
    "\n",
    "**Key Point:**\n",
    "- Each agent does one job, passing structured outputs forward, resulting in a clear, explainable recommendation.\n",
    "- Agents reason and specialize; the **Comparison Manager controls execution**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a086c3",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2500df",
   "metadata": {},
   "source": [
    "## Web search tool\n",
    "\n",
    "- Use either OpenAI's `WebSearchTool` (additional costs)\n",
    "- Or Ollama's web search tool via HTTP call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c748a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ollama's web search\n",
    "@function_tool\n",
    "def web_search(product, search_focus) -> list[dict]:\n",
    "    \"\"\"Web Search Tool via Ollama API\"\"\"\n",
    "\n",
    "    url = \"https://ollama.com/api/web_search\"\n",
    "    headers = {\"Authorization\": f\"Bearer {os.environ.get('OLLAMA_API_KEY_CLOUD')}\",\n",
    "               \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"query\": f\"{product}+{search_focus}\"}\n",
    "    \n",
    "    response = requests.post(url, \n",
    "                             json=payload, \n",
    "                             headers=headers)\n",
    "    \n",
    "    if response.status_code == 202:\n",
    "        return response\n",
    "    else:\n",
    "        return {\"status\": \"failure\", \"message\": response.text}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8aeb5c",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c7e70ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planner Agent\n",
    "\n",
    "NUM_OF_SEARCHES = 1     # limit searches\n",
    "INSTRUCTIONS = f\"Given a consumer product decision query, identify relevant still in production or operation products/ecosystems,\\\n",
    "derive evaluation criteria from stated priorities, and define {NUM_OF_SEARCHES} search per product.\"\n",
    "\n",
    "class ProductPlan(BaseModel):\n",
    "    products: list[str] = Field(description=\"A list of products to search.\")\n",
    "    criteria: list[str] = Field(description=\"A list of priorities for a given product\")\n",
    "    searches: list[str] = Field(description=\"A list of web searches to perfom for a product based on the evaluation criteria.\")\n",
    "\n",
    "planner_agent = Agent(\n",
    "    name=\"Planner Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=MODEL,\n",
    "    output_type=ProductPlan,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "251ad958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Agent\n",
    "\n",
    "INSTRUCTIONS = \"You are a research assistant. Given a search term, you search the web for that term and \\\n",
    "produce a concise summary of the results. The summary must 2-3 paragraphs and less than 300 \\\n",
    "words. Capture the main points. Write succintly, no need to have complete sentences or good \\\n",
    "grammar. This will be consumed by someone synthesizing a report, so it's vital you capture the \\\n",
    "essence and ignore any fluff. Do not include any additional commentary other than the summary itself.\"\n",
    "\n",
    "search_agent = Agent(\n",
    "    name=\"Search agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    # tools=[WebSearchTool(search_context_size=\"low\")]          # OpenAI's tool\n",
    "    tools=[web_search],                                       # Ollama's tool  \n",
    "    model=MODEL,\n",
    "    model_settings=ModelSettings(tool_choice=\"required\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50aaf32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparator Agent\n",
    "\n",
    "INSTRUCTIONS = (\n",
    "    \"You are a decision assistant. Given structured product research summaries, compare products against user priorities.\\n\"\n",
    "    \"Normalize differences, rank options, and recommend the best choice.\\n\"\n",
    "    \"Be concise and decision-oriented.\"\n",
    ")\n",
    "\n",
    "\n",
    "class ComparisonResult(BaseModel):\n",
    "    summary: str = Field(description=\"A summary of the findings with a comparison table, including a best for and tradeoffs sections in markdown format.\")\n",
    "    best_for: list[str]\n",
    "    comparison_table: str = Field(description=\"A comparison table cleaned up, readable, and structured table in markdown format.\")\n",
    "    tradeoffs: list[str] = Field(description=\"A list of tradeoffs.\")\n",
    "    sources: list[str] = Field(description=\"A list of sources used to provide the recommendation.\")\n",
    "\n",
    "comparator_agent = Agent(\n",
    "    name=\"Comparator Agent\",\n",
    "    instructions=INSTRUCTIONS,\n",
    "    model=MODEL,\n",
    "    output_type=ComparisonResult,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187f8927",
   "metadata": {},
   "source": [
    "## Orchestrator - Comparison Manager\n",
    "\n",
    "Note: *full code not provided*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d77b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ComparisonManager:\n",
    "    \"\"\"\n",
    "    Orchestrates the product comparison workflow:\n",
    "    planning → parallel research → comparison.\n",
    "    \"\"\"\n",
    "\n",
    "    async def run(self, query: str):\n",
    "        \"\"\" Run the product comparison process, yielding the status updates and the recommendation\"\"\"\n",
    "        trace_id = gen_trace_id()\n",
    "\n",
    "        with trace(\"Comparison trace\", trace_id=trace_id):\n",
    "            print(f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\")\n",
    "            yield f\"View trace: https://platform.openai.com/traces/trace?trace_id={trace_id}\"\n",
    "            \n",
    "            # 1. Plan\n",
    "            print(\"Starting comparison...\")\n",
    "            search_plan = await self.plan_searches(query)\n",
    "            yield \"Researching products identified...\"   \n",
    "\n",
    "            # 2. Parallel research\n",
    "            research_results = await self.perform_searches(search_plan)\n",
    "            yield \"Research complete. Comparing options...\"\n",
    "\n",
    "            # 3. Compare & decide\n",
    "            comparison = await self.compare(research_results, search_plan.criteria)\n",
    "            yield \"Product comparison completed.\"\n",
    "            \n",
    "            yield \"## Recommendation\"\n",
    "            yield comparison.summary\n",
    "\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc8d57",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223b819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View trace: https://platform.openai.com/traces/trace?trace_id=trace_8306362de1c84e0ca1ab03b263640cb3\n",
      "View trace: https://platform.openai.com/traces/trace?trace_id=trace_8306362de1c84e0ca1ab03b263640cb3\n",
      "Starting comparison...\n",
      "Planning product searches...\n",
      "Will perform 4 searches\n",
      "Researching products identified...\n",
      "Researching...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[non-fatal] Tracing: server error 503, retrying.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching... 1/4 completed\n",
      "Searching... 2/4 completed\n",
      "Searching... 3/4 completed\n",
      "Searching... 4/4 completed\n",
      "Finished searching\n",
      "Research complete. Comparing options...\n",
      "Comparing products...\n",
      "Finished comparing products.\n",
      "Product comparison completed.\n",
      "## Recommendation\n",
      "Only one product summary is available – Noddy.  The description provides no technical detail, so I cannot confirm that it meets the strict privacy, security, and open‑source requirements you listed.  I recommend collecting more info (spec sheet, firmware repo, hardware teardown) for Noddy and then comparing it to other open‑source doorbell projects (e.g., ESP‑Doorbell, Pi‑Doorbell‑V2, OpenDoorbell).  If Noddy does satisfy TLS, AES‑256 at rest, SD‑card/NAS storage, user‑controlled retention, signed OTA, secure boot, tamper‑proof chassis, minimal telemetry, GDPR compliance, and has a transparent privacy policy, it would be the best fit.  Without that evidence, it currently cannot be endorsed. }\n"
     ]
    }
   ],
   "source": [
    "manager = ComparisonManager()\n",
    "query = \"Privacy-focused smart doorbells\"\n",
    "\n",
    "results = []\n",
    "async for update in manager.run(query):\n",
    "    results.append(update)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd20ea58",
   "metadata": {},
   "source": [
    "Below results from UI search:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b19090",
   "metadata": {},
   "source": [
    "![ProductLens Initial search](../img/productlens-result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac317de",
   "metadata": {},
   "source": [
    "![ProductLens result 1](../img/productlens-result1.png)\n",
    "![ProductLens result 2](../img/productlens-result2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048fcee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
