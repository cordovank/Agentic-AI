{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c637bbd5",
   "metadata": {},
   "source": [
    "# Professional Twinbot\n",
    "\n",
    "Create a **Professional Twinbot** using LLMs and Gradio. \n",
    "The chatbot is designed to provide information about my professional background based on a summary text file and a linked PDF profile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77284245",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325193d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a453cca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4289b563",
   "metadata": {},
   "source": [
    "Load variables from `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1e25be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded:\n",
      "- OLLAMA_API_KEY = ollama\n",
      "- OLLAMA_BASE_URL = http://localhost:11434/v1\n",
      "Models:\n",
      "- MODEL_PHI = phi4\n",
      "- MODEL_LLAMA = llama3.1\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_API_KEY = os.getenv('OLLAMA_API_KEY')\n",
    "OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL')\n",
    "\n",
    "MODEL_PHI = os.getenv('MODEL_PHI4_14B')\n",
    "MODEL_LLAMA = os.getenv('MODEL_LLAMA3_8B')\n",
    "\n",
    "try:\n",
    "    print(\"Environment variables loaded:\")\n",
    "    print(f\"- OLLAMA_API_KEY = {OLLAMA_API_KEY}\")\n",
    "    print(f\"- OLLAMA_BASE_URL = {OLLAMA_BASE_URL}\")\n",
    "    print(\"Models:\")\n",
    "    print(f\"- MODEL_PHI = {MODEL_PHI}\")\n",
    "    print(f\"- MODEL_LLAMA = {MODEL_LLAMA}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Parameter(s) not set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8062af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull models from Ollama if not already present. \n",
    "# Replace {model_name} with the actual model needed and run\n",
    "# %ollama pull {model_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f663f35",
   "metadata": {},
   "source": [
    "## Load my professional data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8bd89c",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5d77884",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ffab04",
   "metadata": {},
   "source": [
    "### LinkedIn profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8fa9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc52a41",
   "metadata": {},
   "source": [
    "## Prepare Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e13cd870",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY)\n",
    "# openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6ba4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Nellie Cordova\"\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background, a LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model=MODEL_LLAMA, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e55e0b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Launch the chatbot \n",
    "\n",
    "Now we can ask our twinbot questions about ourselves!\n",
    "\n",
    "Questions to try:\n",
    "- Tell me a bit about yourself.\n",
    "- What is your greatest accomplishment?\n",
    "- What would you say are your top skills?\n",
    "- What is a challenge that you encountered and needed to overcome?\n",
    "- What are you looking for in your next role?\n",
    "\n",
    "\n",
    "Launch the chatbot interface:\n",
    "```python\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed3eb6",
   "metadata": {},
   "source": [
    "Result of the interaction with the Twinbot\n",
    "\n",
    "![Twinbot Interaction Result](../img/twinbot-hi.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189d674",
   "metadata": {},
   "source": [
    "# Evaluate and Improve Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9260a85",
   "metadata": {},
   "source": [
    "Objectives:\n",
    "1. Ask an LLM to evaluate an answer\n",
    "2. Rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c23427",
   "metadata": {},
   "source": [
    "## Evaluator LLM\n",
    "\n",
    "Use a different LLM (Ollama phi4-mini) to evaluate the response from the professional twin chatbot.\n",
    "    \n",
    "- We define a Pydantic model to structure the evaluation response.\n",
    "- The evaluator LLM will assess the quality of the response and determine if it is acceptable or needs improvement providing specific feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e8d7c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pydantic model for evaluation response\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "992cb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02f18945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "48fcdeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = OpenAI(base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4f87727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = evaluator.beta.chat.completions.parse(model=MODEL_PHI, messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f1ebcf",
   "metadata": {},
   "source": [
    "Test the evaluator LLM with a sample question and response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "424dd12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"do you hold a patent?\"\n",
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": question}]\n",
    "response = ollama.chat.completions.create(model=MODEL_LLAMA, messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54dc7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = evaluate(reply, question, messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e2aefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User question:\n",
      " do you hold a patent?\n",
      "\n",
      "\n",
      "Agent reply:\n",
      " As a software engineer and researcher, I've been fortunate to have worked on several interesting projects, but I don't currently hold a patent.\n",
      "\n",
      "That being said, some of my research contributions may be subject to intellectual property protection through pending or filed disclosures. My work with William Paterson University's Data Science Research Project on Analyzing Mental Health Problems in NYC is one such example. However, none of these have been fully developed into patented inventions.\n",
      "\n",
      "If you're interested in learning more about this or related areas, please do reach out and let's discuss!\n",
      "\n",
      "\n",
      "Evaluation:\n",
      " is_acceptable=True feedback=\"The response was well-crafted and accurately aligned with Nellie Cordova’s background as described in the provided summary and LinkedIn profile. Here are some points highlighting its strengths:\\n\\n1. **Authenticity**: The response effectively maintains Nellie's voice by acknowledging her research-oriented experience without overstating claims about holding a patent, which reflects realism given her educational and career history.\\n\\n2. **Transparency and Engagement**: By mentioning the ongoing work and openness to discuss further, the response invites engagement and demonstrates transparency about her intellectual contributions, inviting interested parties to explore potential collaborations or discussions.\\n\\n3. **Relevance**: Referencing a specific research project supports relevance to the question while subtly showcasing Nellie's background in data science and potential areas of interest related to patents.\\n\\nOverall, the response was engaging, truthful, and reflective of Nellie Cordova’s professional persona.\"\n"
     ]
    }
   ],
   "source": [
    "print(\"User question:\\n\", question)\n",
    "print(\"\\n\")\n",
    "print(\"Agent reply:\\n\", reply)\n",
    "print(\"\\n\")\n",
    "print(\"Evaluation:\\n\", feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd5ceb",
   "metadata": {},
   "source": [
    "## Rerun LLM for improved answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c74cf3",
   "metadata": {},
   "source": [
    "If the evaluator LLM indicates that the response is not acceptable, we can rerun the professional twin chatbot to generate an improved answer based on the feedback provided.\n",
    "\n",
    "This involves:\n",
    "1. Checking the evaluation result.\n",
    "2. If not acceptable, modify the prompt or context based on feedback.\n",
    "3. Rerun the professional twin chatbot with the updated prompt or context.\n",
    "4. Iterate this process until an acceptable response is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "48f75e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\n\\\n",
    "    You just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = ollama.chat.completions.create(model=MODEL_LLAMA, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65779e95",
   "metadata": {},
   "source": [
    "For testing purposes, we force the twin chatbot to initially give a poor answer to demonstrate the rerun process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "41e86a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = evaluator.chat.completions.create(model=MODEL_PHI, messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa47e3",
   "metadata": {},
   "source": [
    "Now we can put this all together into a single workflow that asks the professional twinbot a question, evaluates the response, and if necessary, reruns the chatbot to improve the answer based on the evaluation feedback.\n",
    "\n",
    "*Note: The evaluator LLM should be different from the one used for the professional twin chatbot to ensure unbiased evaluation.*\n",
    "\n",
    "\n",
    "We ask the same question again, and internally the workflow will evaluate and rerun as needed to get an acceptable answer.\n",
    "\n",
    "Run:\n",
    "```python\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de73e7",
   "metadata": {},
   "source": [
    "Result of the interaction with the Twinbot for improved responses using the Evaluator:\n",
    "\n",
    "![Evaluator Output](../img/twinbot-evaluator.png)\n",
    "\n",
    "Internally, the workflow evaluated the initial response and determined it was not acceptable. The feedback provided by the evaluator LLM highlighted areas for improvement, leading to a rerun of the professional twin chatbot. The final response was generated after addressing the feedback.\n",
    "\n",
    "Logs:\n",
    "```text\n",
    "Failed evaluation - retrying\n",
    "The response from the Agent contains several areas that could be improved to align better with the expected professionalism and engagement level when representing Nellie on their website:\n",
    "\n",
    "1. **Incorrect Language**: The use of Pig Latin (e.g., \"Ohay eallyray!\") is inappropriate for a professional setting. This style might confuse users and make it seem less serious.\n",
    "\n",
    "2. **Clarity and Professionalism**: While the intent behind discussing innovation and patents seems positive, the response could be unclear to some readers who may not understand the references made due to the Pig Latin translation.\n",
    "\n",
    "3. **Missing Direct Answer**: The user asked a direct question about holding any patents, but this aspect was not directly addressed in the answer. It's important to provide clear answers regarding specific questions when feasible.\n",
    "\n",
    "4. **Content Tone and Relevance**: While creativity can be engaging, it should not overshadow clear communication nor stray too far from the professional focus expected on a corporate or personal portfolio website.\n",
    "\n",
    "Overall, while the underlying message about innovation is appropriate, the presentation needs to be corrected for clarity and professionalism.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
