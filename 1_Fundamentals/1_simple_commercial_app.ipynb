{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95b56bc",
   "metadata": {},
   "source": [
    "# Simple Commercial Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e0c397",
   "metadata": {},
   "source": [
    "> **Goal:** \n",
    "> Create a simple agentic workflow via prompt chaining. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d078985d",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Challenge</h2>\n",
    "            <span style=\"color:#ff7800;\">\n",
    "            <ul>\n",
    "                <li> First, ask LLM1 to pick a business area that might be worth exploring for an Agentic AI opportunity.</li>\n",
    "                <li> Then, ask LLM2 to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.</li>\n",
    "                <li> Fnally, have LLM3 call propose the Agentic AI solution.</li>\n",
    "            </ul>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a59a75",
   "metadata": {},
   "source": [
    "**Prompt Chaining:** Input > LLM1 > LLM2 > â€¦ > Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2222a2",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887e4d5",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8052019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4949550",
   "metadata": {},
   "source": [
    "Check API Keys are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30096bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key not set.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# OpenAI API\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec3a3f",
   "metadata": {},
   "source": [
    "Check Ollama variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9875e6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is set:\n",
      "\t- OLLAMA_BASE_URL = http://localhost:11434/v1\n",
      "\t- OLLAMA_MODEL_LLAMA = llama3.2\n",
      "\t- OLLAMA_MODEL_PHI = phi4-mini\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_API_KEY = os.getenv('OLLAMA_API_KEY')\n",
    "OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL')\n",
    "OLLAMA_MODEL_LLAMA = os.getenv('OLLAMA_MODEL_LLAMA')\n",
    "OLLAMA_MODEL_PHI = os.getenv('OLLAMA_MODEL_PHI')\n",
    "\n",
    "# Check Ollama\n",
    "if OLLAMA_API_KEY and OLLAMA_BASE_URL and OLLAMA_MODEL_LLAMA and OLLAMA_MODEL_PHI:\n",
    "    print(f\"Ollama is set:\")\n",
    "    print(f\"\\t- OLLAMA_BASE_URL = {OLLAMA_BASE_URL}\")\n",
    "    print(f\"\\t- OLLAMA_MODEL_LLAMA = {OLLAMA_MODEL_LLAMA}\")\n",
    "    print(f\"\\t- OLLAMA_MODEL_PHI = {OLLAMA_MODEL_PHI}\")\n",
    "else:\n",
    "    print(\"Ollama parameter(s) not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0db27e",
   "metadata": {},
   "source": [
    "## Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af1787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea2dc22",
   "metadata": {},
   "source": [
    "Client instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a6f28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "ollama = OpenAI(base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673140a",
   "metadata": {},
   "source": [
    "API call - Request and Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4299e0",
   "metadata": {},
   "source": [
    "```python\n",
    "messages = [{\"role\": \"user\", \"content\": \"text here\"}]\n",
    "response = ollama.chat.completions.create(\n",
    "    model=OLLAMA_MODEL, \n",
    "    messages=messages\n",
    "    )\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(content))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6222c70",
   "metadata": {},
   "source": [
    "---\n",
    "# Exercise in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608f3bf",
   "metadata": {},
   "source": [
    "LLM1 picks a business area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384908c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthcare Management\n"
     ]
    }
   ],
   "source": [
    "# First create the messages:\n",
    "question1 = \"Pick a business area that might be worth exploring for an Agentic AI opportunity. Respond only with the business area.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question1}]\n",
    "\n",
    "# Then make the first call:\n",
    "response = ollama.chat.completions.create(\n",
    "    model=OLLAMA_MODEL_LLAMA,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Then read the business idea:\n",
    "business_idea = response.choices[0].message.content\n",
    "print(business_idea)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41350c",
   "metadata": {},
   "source": [
    "LLM2 presents a pain-point in that industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01a57c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = f\"\"\"Business area: {business_idea}.\n",
    "Present a pain-point for the given business area - something challenging that might be ripe for an Agentic solution.\n",
    "Respond only with the pain-point.\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": question2}]\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=OLLAMA_MODEL_LLAMA,\n",
    "    messages=messages\n",
    ")\n",
    "problem = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdef0b",
   "metadata": {},
   "source": [
    "LLM3 proposes an Agentic AI solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f96ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = f\"\"\"Business area: {business_idea}\n",
    "Major pain-point: {problem}\n",
    "Propose an Agentic AI solution for the given business area and its pain-point.\n",
    "Repsond only with the proposed solution as plain text.\n",
    "\"\"\"\n",
    "messages = [{\"role\": \"user\", \"content\": question3}]\n",
    "\n",
    "response = ollama.chat.completions.create(\n",
    "    model=OLLAMA_MODEL_LLAMA,\n",
    "    messages=messages\n",
    ")\n",
    "solution = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9131e49",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b573e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS AREA: Healthcare Management\n",
      "PROBLEM:\n",
      "Managers in healthcare management struggle to manage and optimize staff workflows, resulting in excessive administrative tasks, reduced physician productivity, and delayed patient care due to inefficient resource allocation.\n",
      "PROPOSED SOLUTION:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Introducing \"OptiStaff\" - An Agentic AI-powered Staff Workflow Optimization Solution.\n",
       "\n",
       "**Solution Overview:**\n",
       "\n",
       "OptiStaff utilizes Artificial Intelligence (AI) to analyze and optimize staff workflows, streamlining administrative tasks, boosting physician productivity, and ensuring timely patient care. By leveraging machine learning algorithms and real-time data analytics, OptiStaff identifies opportunities for process improvements, automates routine tasks, and provides personalized recommendations to healthcare managers.\n",
       "\n",
       "**Key Components:**\n",
       "\n",
       "1. **Smart Workforce Modeling:** AI-built workforce models analyze staff availability, skills, and assignments to ensure optimal allocation of resources.\n",
       "2. **Automated Task Assignment:** Machines learn to automatically assign tasks based on patient needs, staff capabilities, and clinical workflows.\n",
       "3. **Real-time Analytics and Reporting:** Advanced analytics provide real-time insights into workflow efficiency, allowing managers to make data-driven decisions.\n",
       "4. **Adaptive Coaching and Feedback:** AI-powered coaching tools offer personalized guidance to healthcare teams, fostering a culture of continuous improvement.\n",
       "5. **Integrations with Existing Systems:** Seamless integrations with electronic health records (EHRs), practice management systems, and other relevant software enable seamless workflow optimization.\n",
       "\n",
       "**Benefits:**\n",
       "\n",
       "1. **Reduced Administrative Burden:** Automates administrative tasks, freeing up staff to focus on high-value patient care activities.\n",
       "2. **Increased Physician Productivity:** Streamlines workflows, allowing physicians to spend more time with patients.\n",
       "3. **Improved Patient Care Outcomes:** Enhanced resource allocation and optimized staffing lead to reduced wait times, improved communication, and enhanced patient satisfaction.\n",
       "4. **Data-Driven Decision Making:** Real-time analytics provide actionable insights for informed decision making.\n",
       "\n",
       "**Implementation Strategy:**\n",
       "\n",
       "1. **Pilot Program:** Roll out the solution in a controlled environment to fine-tune AI models and validate results.\n",
       "2. **Phased Deployment:** Gradually expand the solution across the organization, with phased implementation of new features and functionality.\n",
       "3. **Training and Support:** Provide comprehensive training and support for users, including managers, healthcare teams, and IT staff.\n",
       "\n",
       "By adopting OptiStaff, healthcare management can transform workflows, unlock staff potential, and redefine the patient care experience, leading to improved outcomes, increased efficiency, and sustained success."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "print(\"BUSINESS AREA:\", business_idea)\n",
    "\n",
    "print(\"PROBLEM:\")\n",
    "print(problem)\n",
    "\n",
    "print(\"PROPOSED SOLUTION:\")\n",
    "display(Markdown(solution))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2fc065",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
