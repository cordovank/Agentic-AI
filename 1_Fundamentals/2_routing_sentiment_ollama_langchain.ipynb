{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95b56bc",
   "metadata": {},
   "source": [
    "# Agentic Design Patterns - Routing\n",
    "\n",
    "> *(Input → LLM Router → [Task-specific LLMs] → Output)*\n",
    "\n",
    "> Using Ollama llama3.2 & phi4-mini models via LangChain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa90aa9",
   "metadata": {},
   "source": [
    "## Customer Sentiment Router \n",
    "\n",
    "**Goal:** Auto-route an inbound customer message to the best reply generator based on sentiment + intent.\n",
    "\n",
    "**High-level Flow:** \n",
    "\n",
    "\n",
    "1. **Input (I):** raw message + minimal context (customer id/tier, last order, risk flags).\n",
    "2. **LLM Router:** classifies (sentiment, intent, urgency) and outputs a route.\n",
    "3. **Task-specific LLMs/tools:**\n",
    "    - Apology/Recovery Bot (refund/credit, service failure)\n",
    "    - Recommendation Bot (positive/neutral sentiment, purchase intent)\n",
    "    - Escalation Triage Bot (angry, legal, churn-risk, safety)\n",
    "4. **Output (O):** reply text + action payload (e.g., refund amount, ticket priority).\n",
    "\n",
    "**Routing Targets & Criteria**\n",
    "- Apology → sentiment ∈ [negative, frustrated}; intent ∈ [defect, late delivery, billing error}; urgency ≥ medium\n",
    "- Recommendation → sentiment ∈ {positive, neutral}; intent ∈ {browse, upgrade, add-on}; no open incidents; LTV high.\n",
    "- Escalation → sentiment ∈ {very negative}; intent ∈ {cancellation, chargeback, legal, safety}; toxic language or VIP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2222a2",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d50132",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d7c52857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, json\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain import LLMChain, PromptTemplate\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887e4d5",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8052019",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4949550",
   "metadata": {},
   "source": [
    "Check API Keys are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87e3147",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API_KEY = os.getenv('OLLAMA_API_KEY')\n",
    "OLLAMA_BASE_URL = os.getenv('OLLAMA_BASE_URL')\n",
    "OLLAMA_MODEL_LLAMA = os.getenv('OLLAMA_MODEL_LLAMA')\n",
    "OLLAMA_MODEL_PHI = os.getenv('OLLAMA_MODEL_PHI')\n",
    "\n",
    "# Check Ollama\n",
    "if OLLAMA_API_KEY and OLLAMA_BASE_URL and OLLAMA_MODEL_LLAMA and OLLAMA_MODEL_PHI:\n",
    "    print(f\"Ollama is set:\")\n",
    "    print(f\"\\t- OLLAMA_BASE_URL = {OLLAMA_BASE_URL}\")\n",
    "    print(f\"\\t- OLLAMA_MODEL_LLAMA = {OLLAMA_MODEL_LLAMA}\")\n",
    "    print(f\"\\t- OLLAMA_MODEL_PHI = {OLLAMA_MODEL_PHI}\")\n",
    "else:\n",
    "    print(\"Ollama parameter(s) not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0db27e",
   "metadata": {},
   "source": [
    "## Ollama LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af1787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to pull models locally if needed\n",
    "# !ollama pull llama3.2\n",
    "# !ollama pull phi4-mini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673140a",
   "metadata": {},
   "source": [
    "**API call - Request and Response format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4299e0",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# LangChain ChatOpenAI with Ollama LLMs\n",
    "model = ChatOpenAI(\n",
    "    model=OLLAMA_MODEL_LLAMA, \n",
    "    base_url=OLLAMA_BASE_URL, \n",
    "    api_key=OLLAMA_API_KEY\n",
    ")\n",
    "\n",
    "# Messages can be of 2 formats:\n",
    "# 1. Simple list of dicts\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"text here\"},\n",
    "    {\"role\": \"human\", \"content\": \"text here\"},\n",
    "]\n",
    "# 2. LangChain Message objects\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant that translates English to French.\"),\n",
    "    HumanMessage(\"Translate: I love programming.\"),\n",
    "    AIMessage(\"J'adore la programmation.\"),\n",
    "    HumanMessage(\"Translate: I love building applications.\")\n",
    "]\n",
    "\n",
    "# Invoke the model\n",
    "response = model.invoke(\n",
    "    messages=messages\n",
    "    )\n",
    "\n",
    "display(Markdown(response)) // response is AIMessage content\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6222c70",
   "metadata": {},
   "source": [
    "---\n",
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648a4b80",
   "metadata": {},
   "source": [
    "Create LLM objects for router and task-specific bots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e35dd192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently using Ollama for all roles. Update models as needed.\n",
    "params = {\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_tokens\": 1000\n",
    "}\n",
    "\n",
    "LLMs = {\"ROUTER\": ChatOpenAI(model=OLLAMA_MODEL_LLAMA, base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY, temperature=0.0, max_tokens=1000),\n",
    "        \"BOTS\": {\n",
    "            \"APOLOGY\": ChatOpenAI(model=OLLAMA_MODEL_LLAMA, base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY, **params),\n",
    "            \"RECOMMENDATION\": ChatOpenAI(model=OLLAMA_MODEL_LLAMA, base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY, **params),\n",
    "            \"ESCALATION\": ChatOpenAI(model=OLLAMA_MODEL_LLAMA, base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY, **params)\n",
    "            },\n",
    "        \"DEFAULT\": ChatOpenAI(model=OLLAMA_MODEL_PHI, base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY, **params)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2608f3bf",
   "metadata": {},
   "source": [
    "## Task-specific Bots (specialized LLMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7316636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMBot:\n",
    "    def __init__(self): \n",
    "        self.model = None\n",
    "        self.response = None\n",
    "        self.out_json = None\n",
    " \n",
    "    def build_messages(self, router_response: dict) -> list:\n",
    "        pass\n",
    "    \n",
    "    def get_raw_response(self, messages: list) -> AIMessage:\n",
    "        pass\n",
    " \n",
    "    def handle(self, router_response: dict, context: dict)-> dict:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef129eff",
   "metadata": {},
   "source": [
    "### Apology/Recovery Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "54a30ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_apo = PromptTemplate(\n",
    "    input_variables=[\"router_intent\", \"out_json\"],\n",
    "    template=\"\"\"\n",
    "    Issue summary: \"{router_intent} - <short reason>\n",
    "    Policy: full refund if defect, partial credit if delay < 48h.\n",
    "    Write 60-90 words, sincere tone. Include next step + exact timeline hours.\n",
    "    Output JSON: {out_json}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "out_json_apo = {\n",
    "    \"reply\": \"...\", \n",
    "    \"action\": {\n",
    "        \"type\": \"refund|credit|reship\",\n",
    "        \"amount\": \"...\", \n",
    "        \"sla_hours\": 24\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f9a45283",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApologyBot(LLMBot):\n",
    "    def __init__(self): \n",
    "        self.model = LLMs.get(\"BOTS\").get(\"APOLOGY\")\n",
    "        self.response = None\n",
    "        self.out_json = out_json_apo\n",
    "\n",
    "    def build_messages(self, router_response: dict) -> list:\n",
    "        system_msg = \"You write concise, sincere recovery messages and propose remedies. Return JSON only. No markdown.\"\n",
    "        user_msg = template_apo.format(\n",
    "            router_intent=router_response.get(\"intent\", \"unknown\"),\n",
    "            out_json=json.dumps(self.out_json)\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SystemMessage(content=system_msg),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "\n",
    "    def get_raw_response(self, messages: list) -> AIMessage:\n",
    "        return self.model.invoke(messages=messages)\n",
    "\n",
    "    def handle(self, router_response: dict)-> dict:\n",
    "        messages = self.build_messages(router_response)\n",
    "        response = self.get_raw_response(messages).content\n",
    "        self.response = json.loads(response) if isinstance(response, str) else response\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec903fd",
   "metadata": {},
   "source": [
    "### Recommendation Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6e11c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json_rec = {\n",
    "            \"reply\": \"...\", \n",
    "            \"offers\": [\n",
    "                {\"sku\": \"...\", \"reason\": \"...\"},\n",
    "            ]\n",
    "        }\n",
    "\n",
    "template_rec = PromptTemplate(\n",
    "    input_variables=[\"out_json\"],\n",
    "    template=\"\"\"\n",
    "        Customer profile: {{\"tier\":\"Gold\", \"past_purchases\":[\"Starter Plan\"], \"ltv\":1200}}\n",
    "        Goal: suggest 1 upgrade and 1 add-on; cite 1 benefit each; 1 CTA max.\n",
    "        Output JSON: {out_json}\n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9ac433ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationBot(LLMBot):\n",
    "    def __init__(self): \n",
    "        self.model = LLMs.get(\"BOTS\").get(\"RECOMMENDATION\")\n",
    "        self.response = None\n",
    "        self.out_json = out_json_rec\n",
    "\n",
    "    def build_messages(self, router_response=None) -> list:\n",
    "        system_msg = \"You recommend products based on customer issues. Return JSON only. No markdown.\"\n",
    "        user_msg = template_rec.format(\n",
    "            out_json=json.dumps(self.out_json)\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SystemMessage(content=system_msg),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "    \n",
    "    def get_raw_response(self, messages: list) -> AIMessage:\n",
    "        return self.model.invoke(input=messages)\n",
    "    \n",
    "    def handle(self, router_response=None)-> dict:\n",
    "        messages = self.build_messages()\n",
    "        response = self.get_raw_response(messages).content\n",
    "        self.response = json.loads(response) if isinstance(response, str) else response\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2fc065",
   "metadata": {},
   "source": [
    "### Escalation Triage Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7d6d87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_json_esc = {\n",
    "        \"reply\": \"...\", \n",
    "        \"ticket\": {\n",
    "            \"priority\": \"P1|P2\",\n",
    "            \"category\": \"billing|logistics|legal\",\n",
    "            \"required_fields\": [\"order_id\", \"photos\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "template_esc = PromptTemplate(\n",
    "    input_variables=[\"router_intent\", \"out_json\"],\n",
    "    template=\"\"\"\n",
    "        Intent: \"{router_intent}\"\n",
    "        Do: acknowledge; take ownership; ask exactly 2 clarifying questions; promise human follow-up with a timeline.\n",
    "        Ticket: P1 if very_negative or intent in [\"cancellation\", \"safety\"], else P2; category from intent; required_fields must include \"order_id\".\n",
    "        Output JSON: {out_json}\n",
    "        \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "74907e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EscalationBot(LLMBot):\n",
    "    def __init__(self): \n",
    "        self.model = LLMs.get(\"BOTS\").get(\"ESCALATION\")\n",
    "        self.response = None\n",
    "        self.out_json = out_json_esc\n",
    "\n",
    "    def build_messages(self, router_response: dict) -> list:\n",
    "        system_msg = \"You draft escalation messages and create support tickets. Return JSON only. No markdown.\"\n",
    "        user_msg = template_esc.format(\n",
    "            router_intent=router_response.get(\"intent\", \"unknown\"),\n",
    "            out_json=json.dumps(self.out_json)\n",
    "        )\n",
    "        \n",
    "        return [\n",
    "            SystemMessage(content=system_msg),\n",
    "            HumanMessage(content=user_msg)\n",
    "        ]\n",
    "    \n",
    "    def get_raw_response(self, messages: list) -> AIMessage:\n",
    "        return self.model.invoke(input=messages)\n",
    "    \n",
    "    def handle(self, router_response: dict)-> dict:\n",
    "        messages = self.build_messages(router_response)\n",
    "        response = self.get_raw_response(messages).content\n",
    "        self.response = json.loads(response) if isinstance(response, str) else response\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d1d220",
   "metadata": {},
   "source": [
    "## Router LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "22b5788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_router = PromptTemplate(\n",
    "    input_variables=[\"customer_msg\", \"out_json\"],\n",
    "    template = \"\"\"\n",
    "    You classify the customer message. Return JSON only (no markdown).\n",
    "    Message: {customer_msg}\n",
    "    Context: {{\"customer_tier\":\"Gold\", \"open_ticket\":false, \"ltv\":1200}}\n",
    "    Labels wanted: \n",
    "        - sentiment in [very_negative, negative, neutral, positive], \n",
    "        - intent in [billing_issue, delivery_issue, product_defect, cancellation, purchase_intent, general_question, safety],\n",
    "        - urgency in [low, med, high].\n",
    "\n",
    "    Routing rules (evaluate in order; first match wins):\n",
    "        1) Escalation (hard triggers)\n",
    "            - text contains any of [\"cancel\", \"chargeback\", \"lawyer\", \"attorney\", \"legal\", \"sue\", \"report you\", \"fraud\", \"scam\", \"bbb\", \"ripoff\", \"threat\"]\n",
    "            - OR intent in [cancellation, safety]\n",
    "            - OR sentiment == very_negative\n",
    "        2) Apology (service recovery)\n",
    "            - sentiment == negative\n",
    "            - AND intent in [billing_issue, delivery_issue, product_defect]\n",
    "        3) Recommendation (default)\n",
    "            - sentiment in [neutral, positive]\n",
    "            - OR intent in [purchase_intent, general_question]\n",
    "    \n",
    "    Output JSON: {out_json}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "out_json_router = {\n",
    "    \"sentiment\": \"...\",\n",
    "    \"intent\": \"...\",\n",
    "    \"urgency\": \"...\",\n",
    "    \"route\": \"apology|recommendation|escalation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "806c8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router:\n",
    "    def __init__(self):\n",
    "        self.model = LLMs.get(\"ROUTER\")\n",
    "        self.out_json = out_json_router\n",
    "        self.response = None\n",
    "        self.route = None\n",
    "\n",
    "        # Initialize bots\n",
    "        self.apology_bot = ApologyBot()\n",
    "        self.recommendation_bot = RecommendationBot()\n",
    "        self.escalation_bot = EscalationBot()\n",
    "\n",
    "    def build_messages(self, customer_msg: str) -> list:\n",
    "        system_msg = \"You classify customer messages. Return Output JSON only. No markdown.\"\n",
    "        user_msg = template_router.format(\n",
    "            customer_msg=customer_msg, \n",
    "            out_json=json.dumps(self.out_json)\n",
    "            )\n",
    "\n",
    "        return [\n",
    "            (SystemMessage(content=system_msg)),\n",
    "            (HumanMessage(content=user_msg))\n",
    "        ]\n",
    "\n",
    "    def get_raw_response(self, messages) -> AIMessage:\n",
    "        return self.model.invoke(input=messages)\n",
    "\n",
    "    def classify(self) -> str:\n",
    "        return self.response.get(\"route\", \"escalation\")\n",
    "\n",
    "    def handle(self, customer_msg, context={}):\n",
    "        # Get router response & classify \n",
    "        messages = self.build_messages(customer_msg)\n",
    "        response = (self.get_raw_response(messages)).content\n",
    "        self.response = json.loads(response) if isinstance(response, str) else response\n",
    "        self.route = self.classify()\n",
    "\n",
    "        # # Route to appropriate bot\n",
    "        if self.route == \"apology\":\n",
    "            return self.apology_bot.handle(self.response)\n",
    "        elif self.route == \"recommendation\":\n",
    "            return self.recommendation_bot.handle(self.response)\n",
    "        else:\n",
    "            return self.escalation_bot.handle(self.response)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5d8a6",
   "metadata": {},
   "source": [
    "## Generic Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "71575a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplyCustomer:\n",
    "    def __init__(self):\n",
    "        self.model = LLMs.get(\"DEFAULT\")\n",
    "        self.messages = None\n",
    "\n",
    "    def build_messages(self, bot_intent, bot_response: dict):\n",
    "        system_msg = \"You are a customer support agent. Write a clear, friendly reply based on given context. Return reply only.\"\n",
    "\n",
    "        # Keep only the pieces the writer needs\n",
    "        minimal_context = {\n",
    "            \"bot_type\": bot_intent,\n",
    "            \"reply_hint\": bot_response.get(\"reply\", \"\"),\n",
    "            \"action\": bot_response.get(\"action\", {}),\n",
    "            \"ticket\": bot_response.get(\"ticket\", {}),\n",
    "            \"offers\": bot_response.get(\"offers\", []),\n",
    "        }\n",
    "\n",
    "        # One compact instruction that works for all cases\n",
    "        user_msg = f\"\"\"\n",
    "        Craft the final customer-facing message using the BOT_SUMMARY as context.\n",
    "        BOT_SUMMARY: {minimal_context}\n",
    "\n",
    "        Rules:\n",
    "            - 50–100 words, friendly and professional.\n",
    "            - If bot_type is: \n",
    "                - 'apology': apologize briefly, state remedy/next step, give exact timeline (hours), and politely ask for missing required_fields if any.\n",
    "                - 'escalation': acknowledge, de-escalate, ask exactly 2 concise questions (if needed), state that a specialist will follow up and provide a realistic timeline (hours).\n",
    "                - 'recommendation': thank the customer and present exactly 1 upgrade and 1 add-on with a short benefit and one simple CTA.\n",
    "            - If no name is provided, sign off as 'Customer Service Team'.\n",
    "\n",
    "        Reply: <add your reply here>\n",
    "        Return reply only.\n",
    "        \"\"\"\n",
    "\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ]\n",
    "\n",
    "        return self.messages\n",
    "\n",
    "    def get_response(self, messages) -> str:        \n",
    "        raw_response = self.model.invoke(input=messages)\n",
    "        return raw_response.content.strip()\n",
    "\n",
    "    def handle(self, bot_intent, bot_response: dict) -> str:\n",
    "        self.build_messages(bot_intent, bot_response)\n",
    "        self.response = self.get_response(self.messages)\n",
    "        return self.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee25fa1",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b03215f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "router = Router()\n",
    "replier = ReplyCustomer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "882221c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test messages for each route\n",
    "customer_msg_1 = \"I just received my order, but it arrived late and one item is missing.\"\n",
    "customer_msg_2 = \"So far, I'm happy with my Starter Plan. I would like to know what upgrades or add-ons you would recommend.\"\n",
    "customer_msg_3 = \"The product is defective. I will sue you if you don't refund me immediately!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd70ab59",
   "metadata": {},
   "source": [
    "## Test Case: ApologyBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "03e25532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apology|recommendation|escalation'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_resp_1.get(\"route\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8a27f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_resp_1 = router.handle(customer_msg_1)\n",
    "router_resp_1 = router.response\n",
    "reply_1 = replier.handle(router_resp_1.get(\"route\"), bot_resp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bcca53ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Customer Message:**\n",
       "```\n",
       "I just received my order, but it arrived late and one item is missing.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Router Response:**\n",
       "```\n",
       "{\n",
       "  \"sentiment\": \"negative\",\n",
       "  \"intent\": \"delivery_issue\",\n",
       "  \"urgency\": \"low\",\n",
       "  \"route\": \"apology|recommendation|escalation\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Final Reply:**\n",
       "```\n",
       "Dear Customer,\n",
       "\n",
       "We are truly sorry to hear that there was an issue with the delivery of Order ID #12345. We understand how frustrating this can be and apologize for any inconvenience caused.\n",
       "\n",
       "Could you please confirm if:\n",
       "1. The problem occurred during pickup or after it had been handed over?\n",
       "2. Were photos provided as required?\n",
       "\n",
       "A specialist will follow up on your case within 24 hours to resolve the issue promptly, ensuring that we meet our high standards of service with every order placed through us again in confidence.\n",
       "\n",
       "Thank you for choosing [Your Company Name]. We appreciate your understanding and cooperation during this time.\n",
       "Customer Service Team\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"**Customer Message:**\\n```\\n{customer_msg_1}\\n```\"))\n",
    "display(Markdown(f\"**Router Response:**\\n```\\n{json.dumps(router_resp_1, indent=2)}\\n```\"))\n",
    "display(Markdown(f\"**Final Reply:**\\n```\\n{reply_1}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f861c5",
   "metadata": {},
   "source": [
    "## Test Case: RecommendationBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e2362bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_resp_2 = router.handle(customer_msg_2, context={})\n",
    "router_resp_2 = router.response\n",
    "reply_2 = replier.handle(router_resp_2.get(\"route\"), bot_resp_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0ec2f8ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Customer Message:**\n",
       "```\n",
       "So far, I'm happy with my Starter Plan. I would like to know what upgrades or add-ons you would recommend.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Router Response:**\n",
       "```\n",
       "{\n",
       "  \"sentiment\": \"positive\",\n",
       "  \"intent\": \"general_question\",\n",
       "  \"urgency\": \"low\",\n",
       "  \"route\": \"recommendation\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Final Reply:**\n",
       "```\n",
       "Thank you for reaching out to us! Based on the details in our system about how often you're using various tools like Microsoft Office 365 and Adobe Creative Cloud subscriptions (MacBook Pro), we recommend upgrading to our Professional Plan. This will enhance productivity with more features, giving your work increased efficiency and accuracy.\n",
       "\n",
       "Additionally, consider adding a Premium Support Add-on for personalized assistance from experts around the clock - perfect when you need help without interrupting others or waiting in queues!\n",
       "\n",
       "If you'd like further information on these options: (1) What's included? (2) How do they compare to our Basic Plan?\n",
       "\n",
       "Upgrade Now.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"**Customer Message:**\\n```\\n{customer_msg_2}\\n```\"))\n",
    "display(Markdown(f\"**Router Response:**\\n```\\n{json.dumps(router_resp_2, indent=2)}\\n```\"))\n",
    "display(Markdown(f\"**Final Reply:**\\n```\\n{reply_2}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe965d",
   "metadata": {},
   "source": [
    "## Test Case: EscalationBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cb351158",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_resp_3 = router.handle(customer_msg_3, context={})\n",
    "router_resp_3 = router.response\n",
    "reply_3 = replier.handle(router_resp_3.get(\"route\"), bot_resp_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0119d397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Customer Message:**\n",
       "```\n",
       "The product is defective. I will sue you if you don't refund me immediately!\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Router Response:**\n",
       "```\n",
       "{\n",
       "  \"sentiment\": \"very_negative\",\n",
       "  \"intent\": \"product_defect\",\n",
       "  \"urgency\": \"high\",\n",
       "  \"route\": \"escalation\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Final Reply:**\n",
       "```\n",
       "Thank you for reporting this issue. I am taking ownership of the ticket to resolve it promptly.\n",
       "\n",
       "Could you please provide us with:\n",
       "1. The order ID associated with these issues?\n",
       "2. If available, any photos that illustrate what you've encountered?\n",
       "\n",
       "A specialist will follow up on your concerns within 24 hours and work diligently towards a resolution for both Priority P1 and P2 tickets in the billing category.\n",
       "\n",
       "\n",
       "\n",
       "Thank you so much! As an upgrade to enhance our service experience further (and possibly save some time), we highly recommend [Upgrade Name] with its key feature of faster processing. Additionally, if you'd like more convenience at home or on-the-go, consider adding [Add-On Name], which provides amazing benefits for your daily needs.\n",
       "\n",
       "If there's anything else I can assist you with today apart from this issue!\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"**Customer Message:**\\n```\\n{customer_msg_3}\\n```\"))\n",
    "display(Markdown(f\"**Router Response:**\\n```\\n{json.dumps(router_resp_3, indent=2)}\\n```\"))\n",
    "display(Markdown(f\"**Final Reply:**\\n```\\n{reply_3}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cfc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
